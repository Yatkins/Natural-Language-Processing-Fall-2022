{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Z2crmXfkHvj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4d6a9e-8d13-4543-ccf6-ccf41b5eaa08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download(\"wordnet\")\n",
        "import urllib.request\n",
        "from nltk.corpus import wordnet\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "wordsim_url = \"http://www.cs.columbia.edu/~sarahita/CL/wordsim-353.txt\"\n",
        "\n",
        "# read url .txt file into string \"data\"\n",
        "def get_data(url):\n",
        "  data = urllib.request.urlopen(url).read().decode('utf-8')\n",
        "  return data\n",
        "\n",
        "wordsim_data = get_data(wordsim_url)"
      ],
      "metadata": {
        "id": "xMgtuMxNKoHu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Human calculated similarity"
      ],
      "metadata": {
        "id": "L5m3fhzBlFAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordsim_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "QsBDd546KumN",
        "outputId": "9579b9c8-8e9f-4c19-8674-a19973f1c715"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tiger\\tcat\\t7.35\\ntiger\\ttiger\\t10.00\\nplane\\tcar\\t5.77\\ntrain\\tcar\\t6.31\\ntelevision\\tradio\\t6.77\\nmedia\\tradio\\t7.42\\nbread\\tbutter\\t6.19\\ncucumber\\tpotato\\t5.92\\ndoctor\\tnurse\\t7.00\\nprofessor\\tdoctor\\t6.62\\nstudent\\tprofessor\\t6.81\\nsmart\\tstupid\\t5.81\\nwood\\tforest\\t7.73\\nmoney\\tcash\\t9.15\\nking\\tqueen\\t8.58\\nking\\trook\\t5.92\\nbishop\\trabbi\\t6.69\\nfuck\\tsex\\t9.44\\nfootball\\tsoccer\\t9.03\\nfootball\\tbasketball\\t6.81\\nfootball\\ttennis\\t6.63\\nArafat\\tJackson\\t2.50\\nphysics\\tchemistry\\t7.35\\nvodka\\tgin\\t8.46\\nvodka\\tbrandy\\t8.13\\ndrink\\teat\\t6.87\\ncar\\tautomobile\\t8.94\\ngem\\tjewel\\t8.96\\njourney\\tvoyage\\t9.29\\nboy\\tlad\\t8.83\\ncoast\\tshore\\t9.10\\nasylum\\tmadhouse\\t8.87\\nmagician\\twizard\\t9.02\\nmidday\\tnoon\\t9.29\\nfurnace\\tstove\\t8.79\\nfood\\tfruit\\t7.52\\nbird\\tcock\\t7.10\\nbird\\tcrane\\t7.38\\nfood\\trooster\\t4.42\\nmoney\\tdollar\\t8.42\\nmoney\\tcurrency\\t9.04\\ntiger\\tjaguar\\t8.00\\ntiger\\tfeline\\t8.00\\ntiger\\tcarnivore\\t7.08\\ntiger\\tmammal\\t6.85\\ntiger\\tanimal\\t7.00\\ntiger\\torganism\\t4.77\\ntiger\\tfauna\\t5.62\\npsychology\\tpsychiatry\\t8.08\\npsychology\\tscience\\t6.71\\npsychology\\tdiscipline\\t5.58\\nplanet\\tstar\\t8.45\\nplanet\\tmoon\\t8.08\\nplanet\\tsun\\t8.02\\nprecedent\\texample\\t5.85\\nprecedent\\tantecedent\\t6.04\\ncup\\ttableware\\t6.85\\ncup\\tartifact\\t2.92\\ncup\\tobject\\t3.69\\ncup\\tentity\\t2.15\\njaguar\\tcat\\t7.42\\njaguar\\tcar\\t7.27\\nmile\\tkilometer\\t8.66\\nskin\\teye\\t6.22\\nJapanese\\tAmerican\\t6.50\\ncentury\\tyear\\t7.59\\nannouncement\\tnews\\t7.56\\ndoctor\\tpersonnel\\t5.00\\nHarvard\\tYale\\t8.13\\nhospital\\tinfrastructure\\t4.63\\nlife\\tdeath\\t7.88\\ntravel\\tactivity\\t5.00\\ntype\\tkind\\t8.97\\nstreet\\tplace\\t6.44\\nstreet\\tavenue\\t8.88\\nstreet\\tblock\\t6.88\\ncell\\tphone\\t7.81\\ndividend\\tpayment\\t7.63\\ncalculation\\tcomputation\\t8.44\\nprofit\\tloss\\t7.63\\ndollar\\tyen\\t7.78\\ndollar\\tbuck\\t9.22\\nphone\\tequipment\\t7.13\\nliquid\\twater\\t7.89\\nmarathon\\tsprint\\t7.47\\nseafood\\tfood\\t8.34\\nseafood\\tlobster\\t8.70\\nlobster\\tfood\\t7.81\\nlobster\\twine\\t5.70\\nchampionship\\ttournament\\t8.36\\nman\\twoman\\t8.30\\nman\\tgovernor\\t5.25\\nmurder\\tmanslaughter\\t8.53\\nopera\\tperformance\\t6.88\\nMexico\\tBrazil\\t7.44\\nglass\\tmetal\\t5.56\\naluminum\\tmetal\\t7.83\\nrock\\tjazz\\t7.59\\nmuseum\\ttheater\\t7.19\\nshower\\tthunderstorm\\t6.31\\nmonk\\toracle\\t5.00\\ncup\\tfood\\t5.00\\njournal\\tassociation\\t4.97\\nstreet\\tchildren\\t4.94\\ncar\\tflight\\t4.94\\nspace\\tchemistry\\t4.88\\nsituation\\tconclusion\\t4.81\\nword\\tsimilarity\\t4.75\\npeace\\tplan\\t4.75\\nconsumer\\tenergy\\t4.75\\nministry\\tculture\\t4.69\\nsmart\\tstudent\\t4.62\\ninvestigation\\teffort\\t4.59\\nimage\\tsurface\\t4.56\\nlife\\tterm\\t4.50\\nstart\\tmatch\\t4.47\\ncomputer\\tnews\\t4.47\\nboard\\trecommendation\\t4.47\\nlad\\tbrother\\t4.46\\nobservation\\tarchitecture\\t4.38\\ncoast\\thill\\t4.38\\ndeployment\\tdeparture\\t4.25\\nbenchmark\\tindex\\t4.25\\nattempt\\tpeace\\t4.25\\nconsumer\\tconfidence\\t4.13\\nstart\\tyear\\t4.06\\nfocus\\tlife\\t4.06\\ndevelopment\\tissue\\t3.97\\ntheater\\thistory\\t3.91\\nsituation\\tisolation\\t3.88\\nprofit\\twarning\\t3.88\\nmedia\\ttrading\\t3.88\\nchance\\tcredibility\\t3.88\\nprecedent\\tinformation\\t3.85\\narchitecture\\tcentury\\t3.78\\npopulation\\tdevelopment\\t3.75\\nstock\\tlive\\t3.73\\npeace\\tatmosphere\\t3.69\\nmorality\\tmarriage\\t3.69\\nminority\\tpeace\\t3.69\\natmosphere\\tlandscape\\t3.69\\nreport\\tgain\\t3.63\\nmusic\\tproject\\t3.63\\nseven\\tseries\\t3.56\\nexperience\\tmusic\\t3.47\\nschool\\tcenter\\t3.44\\nfive\\tmonth\\t3.38\\nannouncement\\tproduction\\t3.38\\nmorality\\timportance\\t3.31\\nmoney\\toperation\\t3.31\\ndelay\\tnews\\t3.31\\ngovernor\\tinterview\\t3.25\\npractice\\tinstitution\\t3.19\\ncentury\\tnation\\t3.16\\ncoast\\tforest\\t3.15\\nshore\\twoodland\\t3.08\\ndrink\\tcar\\t3.04\\npresident\\tmedal\\t3.00\\nprejudice\\trecognition\\t3.00\\nviewer\\tserial\\t2.97\\npeace\\tinsurance\\t2.94\\nMars\\twater\\t2.94\\nmedia\\tgain\\t2.88\\nprecedent\\tcognition\\t2.81\\nannouncement\\teffort\\t2.75\\nline\\tinsurance\\t2.69\\ncrane\\timplement\\t2.69\\ndrink\\tmother\\t2.65\\nopera\\tindustry\\t2.63\\nvolunteer\\tmotto\\t2.56\\nlisting\\tproximity\\t2.56\\nprecedent\\tcollection\\t2.50\\ncup\\tarticle\\t2.40\\nsign\\trecess\\t2.38\\nproblem\\tairport\\t2.38\\nreason\\thypertension\\t2.31\\ndirection\\tcombination\\t2.25\\nWednesday\\tnews\\t2.22\\nglass\\tmagician\\t2.08\\ncemetery\\twoodland\\t2.08\\npossibility\\tgirl\\t1.94\\ncup\\tsubstance\\t1.92\\nforest\\tgraveyard\\t1.85\\nstock\\tegg\\t1.81\\nmonth\\thotel\\t1.81\\nenergy\\tsecretary\\t1.81\\nprecedent\\tgroup\\t1.77\\nproduction\\thike\\t1.75\\nstock\\tphone\\t1.62\\nholy\\tsex\\t1.62\\nstock\\tCD\\t1.31\\ndrink\\tear\\t1.31\\ndelay\\tracism\\t1.19\\nstock\\tlife\\t0.92\\nstock\\tjaguar\\t0.92\\nmonk\\tslave\\t0.92\\nlad\\twizard\\t0.92\\nsugar\\tapproach\\t0.88\\nrooster\\tvoyage\\t0.62\\nnoon\\tstring\\t0.54\\nchord\\tsmile\\t0.54\\nprofessor\\tcucumber\\t0.31\\nking\\tcabbage\\t0.23\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordsim_parsed = [line.split('\\t') for line in wordsim_data.splitlines()]"
      ],
      "metadata": {
        "id": "Tbmyz39OKzdF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector of human calculated similarity"
      ],
      "metadata": {
        "id": "bpoWJFvas6g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extract all similarities into a similarity array\n",
        "\n",
        "human_sim = []\n",
        "\n",
        "for [word1,word2,sim] in wordsim_parsed:\n",
        "  human_sim.append(float(sim))\n",
        "\n",
        "print(human_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cMolGUBLD_q",
        "outputId": "0ece79d0-ecae-4f0c-85ee-45ccc9f9e222"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.35, 10.0, 5.77, 6.31, 6.77, 7.42, 6.19, 5.92, 7.0, 6.62, 6.81, 5.81, 7.73, 9.15, 8.58, 5.92, 6.69, 9.44, 9.03, 6.81, 6.63, 2.5, 7.35, 8.46, 8.13, 6.87, 8.94, 8.96, 9.29, 8.83, 9.1, 8.87, 9.02, 9.29, 8.79, 7.52, 7.1, 7.38, 4.42, 8.42, 9.04, 8.0, 8.0, 7.08, 6.85, 7.0, 4.77, 5.62, 8.08, 6.71, 5.58, 8.45, 8.08, 8.02, 5.85, 6.04, 6.85, 2.92, 3.69, 2.15, 7.42, 7.27, 8.66, 6.22, 6.5, 7.59, 7.56, 5.0, 8.13, 4.63, 7.88, 5.0, 8.97, 6.44, 8.88, 6.88, 7.81, 7.63, 8.44, 7.63, 7.78, 9.22, 7.13, 7.89, 7.47, 8.34, 8.7, 7.81, 5.7, 8.36, 8.3, 5.25, 8.53, 6.88, 7.44, 5.56, 7.83, 7.59, 7.19, 6.31, 5.0, 5.0, 4.97, 4.94, 4.94, 4.88, 4.81, 4.75, 4.75, 4.75, 4.69, 4.62, 4.59, 4.56, 4.5, 4.47, 4.47, 4.47, 4.46, 4.38, 4.38, 4.25, 4.25, 4.25, 4.13, 4.06, 4.06, 3.97, 3.91, 3.88, 3.88, 3.88, 3.88, 3.85, 3.78, 3.75, 3.73, 3.69, 3.69, 3.69, 3.69, 3.63, 3.63, 3.56, 3.47, 3.44, 3.38, 3.38, 3.31, 3.31, 3.31, 3.25, 3.19, 3.16, 3.15, 3.08, 3.04, 3.0, 3.0, 2.97, 2.94, 2.94, 2.88, 2.81, 2.75, 2.69, 2.69, 2.65, 2.63, 2.56, 2.56, 2.5, 2.4, 2.38, 2.38, 2.31, 2.25, 2.22, 2.08, 2.08, 1.94, 1.92, 1.85, 1.81, 1.81, 1.81, 1.77, 1.75, 1.62, 1.62, 1.31, 1.31, 1.19, 0.92, 0.92, 0.92, 0.92, 0.88, 0.62, 0.54, 0.54, 0.31, 0.23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wordnet Similarity"
      ],
      "metadata": {
        "id": "lPI1MALFlKI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#manually calculte wordnet sim for words in table\n",
        "\n",
        "syn1 = wordnet.synsets(\"jaguar\")[0]\n",
        "syn2 = wordnet.synsets(\"cat\")[0]\n",
        "print(\"jaguar and cat\", round(syn1.wup_similarity(syn2), 3))\n",
        "\n",
        "syn1 = wordnet.synsets(\"jaguar\")[0]\n",
        "syn2 = wordnet.synsets(\"car\")[0]\n",
        "print(\"jaguar and car\", round(syn1.wup_similarity(syn2), 3))\n",
        "\n",
        "syn1 = wordnet.synsets(\"king\")[0]\n",
        "syn2 = wordnet.synsets(\"queen\")[0]\n",
        "print(\"king and queen\", round(syn1.wup_similarity(syn2), 3))\n",
        "\n",
        "syn1 = wordnet.synsets(\"king\")[0]\n",
        "syn2 = wordnet.synsets(\"rook\")[0]\n",
        "print(\"king and rook\", round(syn1.wup_similarity(syn2), 3))\n",
        "\n",
        "syn1 = wordnet.synsets(\"tiger\")[0]\n",
        "syn2 = wordnet.synsets(\"zoo\")[0]\n",
        "print(\"tiger and zoo\", round(syn1.wup_similarity(syn2), 3))\n",
        "\n",
        "syn1 = wordnet.synsets(\"tiger\")[0]\n",
        "syn2 = wordnet.synsets(\"cat\")[0]\n",
        "print(\"tiger and cat\", round(syn1.wup_similarity(syn2), 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf26hLW_PuKi",
        "outputId": "ed22a39c-9bd8-45e3-fa2b-de10ea7b1c33"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jaguar and cat 0.897\n",
            "jaguar and car 0.308\n",
            "king and queen 0.571\n",
            "king and rook 0.381\n",
            "tiger and zoo 0.533\n",
            "tiger and cat 0.545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector for all wordnet sim"
      ],
      "metadata": {
        "id": "B9tthgjXlPLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loop through all words to calculate wordnet sim\n",
        "\n",
        "wordnet_sim = []\n",
        "\n",
        "for [word1,word2,sim] in wordsim_parsed:\n",
        "  syn1 = wordnet.synsets(word1)[0]\n",
        "  syn2 = wordnet.synsets(word2)[0]\n",
        "  similarity = round(syn1.wup_similarity(syn2), 3)\n",
        "  wordnet_sim.append(similarity)\n",
        "\n",
        "print(wordnet_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hDL_L5NKKuW",
        "outputId": "ee3b6018-58d6-4e89-9a15-6e206ab5c29c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.545, 0.75, 0.667, 0.667, 0.9, 0.824, 0.75, 0.2, 0.87, 0.5, 0.571, 0.133, 0.286, 0.8, 0.571, 0.381, 0.545, 0.857, 0.96, 0.783, 0.783, 0.571, 0.9, 0.909, 0.909, 0.182, 1.0, 0.588, 0.857, 0.667, 0.909, 0.632, 0.632, 1.0, 0.455, 0.286, 0.211, 0.6, 0.211, 0.429, 0.857, 0.522, 0.571, 0.6, 0.667, 0.8, 0.857, 0.2, 0.727, 0.941, 0.875, 0.857, 0.8, 0.8, 0.923, 0.154, 0.889, 0.769, 0.545, 0.222, 0.897, 0.308, 0.8, 0.588, 0.632, 0.833, 0.667, 0.133, 0.889, 0.125, 0.308, 0.667, 0.947, 0.4, 0.1, 0.667, 0.375, 0.421, 1.0, 0.5, 0.267, 0.111, 0.875, 0.471, 0.5, 0.545, 0.857, 0.462, 0.375, 0.286, 0.667, 0.632, 0.917, 0.286, 0.8, 0.545, 0.933, 0.143, 0.625, 0.235, 0.571, 0.308, 0.333, 0.444, 0.118, 0.286, 0.286, 0.333, 0.308, 0.308, 0.533, 0.133, 0.353, 0.154, 0.308, 0.125, 0.133, 0.25, 0.6, 0.125, 0.667, 0.714, 0.769, 0.308, 0.133, 0.308, 0.267, 0.375, 0.143, 0.727, 0.222, 0.133, 0.5, 0.333, 0.143, 0.267, 0.182, 0.667, 0.462, 0.364, 0.125, 0.333, 0.308, 0.286, 0.333, 0.133, 0.429, 0.333, 0.667, 0.308, 0.333, 0.118, 0.308, 0.286, 0.167, 0.6, 0.111, 0.118, 0.267, 0.143, 0.308, 0.267, 0.167, 0.727, 0.308, 0.308, 0.471, 0.118, 0.267, 0.133, 0.25, 0.364, 0.625, 0.286, 0.133, 0.267, 0.167, 0.267, 0.333, 0.429, 0.133, 0.333, 0.133, 0.118, 0.143, 0.286, 0.4, 0.588, 0.125, 0.308, 0.4, 0.133, 0.267, 0.308, 0.091, 0.667, 0.667, 0.1, 0.08, 0.111, 0.286, 0.5, 0.25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Similarity"
      ],
      "metadata": {
        "id": "FEANGtEulauA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load pre-trained model\n",
        "\n",
        "wv_model = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "metadata": {
        "id": "h5-fE8jEXSjz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#manually calculte cosine sim for words in table\n",
        "\n",
        "print(\"jaguar and cat\",  round(wv_model.similarity('jaguar', 'cat'),3))\n",
        "print(\"jaguar and car\",  round(wv_model.similarity('jaguar', 'car'),3))\n",
        "print(\"king and queen\",  round(wv_model.similarity('king', 'queen'),3))\n",
        "print(\"king and rook\",  round(wv_model.similarity('king', 'rook'),3))\n",
        "print(\"tiger and zoo\",  round(wv_model.similarity('tiger', 'zoo'),3))\n",
        "print(\"tiger and cat\",  round(wv_model.similarity('tiger', 'cat'),3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9umn2BGP1iW",
        "outputId": "554158e2-d0a8-427f-c173-0207d2b03762"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jaguar and cat 0.373\n",
            "jaguar and car 0.475\n",
            "king and queen 0.784\n",
            "king and rook 0.254\n",
            "tiger and zoo 0.367\n",
            "tiger and cat 0.615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity vector"
      ],
      "metadata": {
        "id": "RPf4VpIkle4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loop through all words to compute cosine similarity between 2 words\n",
        "\n",
        "cosine_sim = []\n",
        "\n",
        "for [word1,word2,sim] in wordsim_parsed:\n",
        "  if word1 and word2 in wv_model.vocab:\n",
        "    similarity = round(wv_model.similarity(word1.lower(), word2.lower()),3)\n",
        "    cosine_sim.append(similarity)\n",
        "  else:\n",
        "    cosine_sim.append(None)\n",
        "\n",
        "print(cosine_sim)"
      ],
      "metadata": {
        "id": "MIrSGQUNV3ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da56db5-8e78-45b5-aeb2-f6c6f012d8f4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.615, 1.0, 0.666, 0.766, 0.871, 0.761, 0.84, 0.712, 0.798, 0.582, 0.672, 0.618, 0.585, 0.899, 0.784, 0.254, 0.504, 0.165, 0.896, 0.879, 0.597, None, 0.9, 0.661, 0.716, 0.751, 0.696, 0.739, 0.827, 0.428, 0.793, -0.274, 0.724, 0.83, 0.665, 0.676, 0.232, 0.449, -0.025, 0.6, 0.534, 0.404, 0.303, 0.181, 0.341, 0.454, 0.076, 0.269, 0.804, 0.829, 0.526, 0.476, 0.652, 0.52, 0.518, 0.345, 0.098, -0.046, 0.058, 0.057, 0.373, 0.475, 0.875, 0.741, None, 0.502, 0.687, 0.342, None, 0.326, 0.726, 0.47, 0.643, 0.583, 0.797, 0.604, 0.604, 0.689, 0.74, 0.672, 0.745, 0.206, 0.586, 0.72, 0.674, 0.734, 0.745, 0.41, 0.474, 0.883, 0.886, 0.405, 0.727, 0.557, None, 0.771, 0.733, 0.729, 0.652, 0.453, 0.051, 0.318, 0.572, 0.356, 0.536, 0.333, 0.692, 0.498, 0.676, 0.635, 0.464, 0.407, 0.576, 0.479, 0.657, 0.69, 0.531, 0.73, 0.248, 0.395, 0.459, 0.57, 0.868, 0.607, 0.653, 0.783, 0.68, 0.538, 0.376, 0.612, 0.393, 0.506, 0.54, 0.339, 0.702, 0.489, 0.271, 0.456, 0.489, 0.452, 0.522, 0.447, 0.528, 0.689, 0.559, 0.679, 0.764, 0.432, 0.518, 0.511, 0.451, 0.458, 0.498, 0.541, 0.627, 0.409, 0.437, 0.313, 0.392, 0.336, 0.161, 0.392, 0.509, 0.194, 0.515, 0.393, -0.087, 0.41, 0.327, 0.378, 0.302, 0.213, 0.172, 0.268, 0.306, 0.185, 0.53, 0.745, 0.154, 0.517, 0.299, 0.26, 0.34, 0.221, 0.469, 0.392, 0.193, 0.388, 0.524, 0.338, None, 0.352, 0.175, 0.388, 0.208, 0.433, 0.373, 0.137, 0.011, 0.22, 0.242, -0.13, 0.113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate! Calculate spearman correlation and covergae percentage"
      ],
      "metadata": {
        "id": "wbSBgKBElizC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats"
      ],
      "metadata": {
        "id": "6IjSvb_4gaH_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_to_drop = []\n",
        "\n",
        "for i, j in enumerate(cosine_sim):\n",
        "    if j == None:\n",
        "        indices_to_drop.append(i)"
      ],
      "metadata": {
        "id": "uvxHD36OmulT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#work backwords because removing values changes the indices\n",
        "for i in reversed(indices_to_drop):\n",
        "  del cosine_sim[i]"
      ],
      "metadata": {
        "id": "2uLHxjqSno-s"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate coverage\n",
        "\n",
        "wordnet_coverage = len(wordnet_sim)/len(human_sim)\n",
        "print(\"wordnet coverag \", wordnet_coverage)\n",
        "\n",
        "cosine_coverage = len(cosine_sim)/len(human_sim)\n",
        "print(\"cosine_coverage \", cosine_coverage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUDEH8ZlsX2b",
        "outputId": "fe67e9e9-8e34-40d0-fb91-8bcaf8ee2d27"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wordnet coverag  1.0\n",
            "cosine_coverage  0.9753694581280788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in reversed(indices_to_drop):\n",
        "  del human_sim[i]\n",
        "  del wordnet_sim[i]"
      ],
      "metadata": {
        "id": "qY4VsAtNsa1p"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"wordnet: \", stats.spearmanr(human_sim, wordnet_sim))\n",
        "\n",
        "print(\"cosine: \", stats.spearmanr(human_sim, cosine_sim))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoAF-vKGhjsj",
        "outputId": "3078f737-4fa4-4f7e-d3a6-1a92e083db46"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wordnet:  SpearmanrResult(correlation=0.5397881028176145, pvalue=2.2850506268098815e-16)\n",
            "cosine:  SpearmanrResult(correlation=0.5599670080836248, pvalue=9.756241631779086e-18)\n"
          ]
        }
      ]
    }
  ]
}